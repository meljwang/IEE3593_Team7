{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0627b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a30cee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_PATH = BASE_DIR / \"dataset\" / \"card_usage\" / \"card_subway_with_timeseries_features.csv\"\n",
    "OUT_DIR = BASE_DIR / \"ml_outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATE_COL = \"date\"\n",
    "TARGET_COL = \"total_flow\"\n",
    "\n",
    "SEQ_LEN = 14\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08f98d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATE_COL = \"date\"\n",
    "TARGET_COL = \"total_flow\"\n",
    "\n",
    "ROOT = Path.cwd().parent   \n",
    "DATA_PATH = ROOT / \"dataset\" / \"card_usage\" / \"card_subway_transform_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[DATE_COL], low_memory=False)\n",
    "\n",
    "\n",
    "# numeric cleanup\n",
    "for col in [\"boardings\", \"alightings\", \"latitude\", \"longitude\", \"station_code\", \"seoulmetro_code\", TARGET_COL]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# weekend -> int\n",
    "if \"is_weekend\" in df.columns:\n",
    "    df[\"is_weekend\"] = pd.to_numeric(df[\"is_weekend\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "else:\n",
    "    df[\"is_weekend\"] = (df[DATE_COL].dt.weekday >= 5).astype(int)\n",
    "\n",
    "# station_key\n",
    "code = None\n",
    "if \"seoulmetro_code\" in df.columns:\n",
    "    code = df[\"seoulmetro_code\"]\n",
    "elif \"station_code\" in df.columns:\n",
    "    code = df[\"station_code\"]\n",
    "\n",
    "if code is not None:\n",
    "    code_int = code.fillna(-1).astype(int)\n",
    "    df[\"station_key\"] = np.where(\n",
    "        code.notna() & (code.astype(float) > 0),\n",
    "        code_int.astype(str),\n",
    "        df[\"line\"].astype(str) + \"|\" + df[\"station_kr\"].astype(str)\n",
    "    )\n",
    "else:\n",
    "    df[\"station_key\"] = df[\"line\"].astype(str) + \"|\" + df[\"station_kr\"].astype(str)\n",
    "\n",
    "df = df.sort_values([\"station_key\", DATE_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e25a7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df[\"day_of_week_num\"] = df[DATE_COL].dt.dayofweek\n",
    "df[\"day_of_month\"] = df[DATE_COL].dt.day\n",
    "df[\"week_of_year\"] = df[DATE_COL].dt.isocalendar().week.astype(int)\n",
    "df[\"flow_ratio\"] = df[\"boardings\"] / (df[\"alightings\"] + 1)\n",
    "df[\"flow_diff\"] = df[\"boardings\"] - df[\"alightings\"]\n",
    "\n",
    "LAGS = [1, 7, 14]\n",
    "for lag in LAGS:\n",
    "    df[f\"flow_lag_{lag}\"] = df.groupby(\"station_key\")[TARGET_COL].shift(lag)\n",
    "\n",
    "ROLL_WINDOWS = [7, 14]\n",
    "for w in ROLL_WINDOWS:\n",
    "    df[f\"flow_roll_mean_{w}\"] = df.groupby(\"station_key\")[TARGET_COL].transform(\n",
    "        lambda s: s.shift(1).rolling(w, min_periods=w).mean()\n",
    "    )\n",
    "    df[f\"flow_roll_std_{w}\"] = df.groupby(\"station_key\")[TARGET_COL].transform(\n",
    "        lambda s: s.shift(1).rolling(w, min_periods=w).std()\n",
    "    )\n",
    "\n",
    "# Target: next day flow\n",
    "df[\"target\"] = df.groupby(\"station_key\")[TARGET_COL].shift(-1)\n",
    "\n",
    "FEATURES = [\n",
    "    \"flow_lag_1\", \"flow_lag_7\", \"flow_lag_14\",\n",
    "    \"flow_roll_mean_7\", \"flow_roll_mean_14\",\n",
    "    \"flow_roll_std_7\", \"flow_roll_std_14\",\n",
    "    \"flow_ratio\", \"flow_diff\",\n",
    "    \"day_of_week_num\", \"day_of_month\", \"week_of_year\",\n",
    "    \"is_weekend\"\n",
    "]\n",
    "for g in [\"latitude\", \"longitude\"]:\n",
    "    if g in df.columns:\n",
    "        FEATURES.append(g)\n",
    "\n",
    "needed = FEATURES + [\"target\", DATE_COL, \"station_key\"]\n",
    "df_model = df.dropna(subset=needed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c511cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (flow_lag_1) BEFORE LSTM:\n",
      "MAE  : 11,342.17\n",
      "RMSE : 23,829.96\n",
      "----------------------------------------\n",
      "Using features: ['is_weekend', 'day_of_week_num', 'day_of_month', 'week_of_year', 'flow_lag_1', 'flow_lag_7', 'flow_lag_14', 'flow_roll_mean_7', 'flow_roll_mean_14', 'flow_roll_std_7', 'flow_roll_std_14', 'flow_ratio', 'flow_diff', 'latitude', 'longitude']\n"
     ]
    }
   ],
   "source": [
    "# Time split\n",
    "split_date = df_model[DATE_COL].quantile(0.8)\n",
    "train_df = df_model[df_model[DATE_COL] <= split_date].copy()\n",
    "val_df = df_model[df_model[DATE_COL] > split_date].copy()\n",
    "\n",
    "# Per-station normalization\n",
    "stats = train_df.groupby(\"station_key\")[TARGET_COL].agg([\"mean\", \"std\"]).reset_index()\n",
    "stats[\"std\"] = stats[\"std\"].replace(0, np.nan)\n",
    "stats = stats.fillna({\"std\": 1.0})\n",
    "\n",
    "train_df = train_df.merge(stats, on=\"station_key\", how=\"left\")\n",
    "val_df = val_df.merge(stats, on=\"station_key\", how=\"left\")\n",
    "\n",
    "train_df[\"flow_norm\"] = (train_df[TARGET_COL] - train_df[\"mean\"]) / train_df[\"std\"]\n",
    "val_df[\"flow_norm\"] = (val_df[TARGET_COL] - val_df[\"mean\"]) / val_df[\"std\"]\n",
    "\n",
    "val_df[\"mean\"] = val_df[\"mean\"].fillna(val_df[TARGET_COL].mean())\n",
    "val_df[\"std\"] = val_df[\"std\"].fillna(val_df[TARGET_COL].std() if val_df[TARGET_COL].std() > 0 else 1.0)\n",
    "val_df[\"flow_norm\"] = (val_df[TARGET_COL] - val_df[\"mean\"]) / val_df[\"std\"]\n",
    "\n",
    "# Filter out rows with NaN flow_lag_1 to match LGBM baseline\n",
    "val_df = val_df[val_df[\"flow_lag_1\"].notna()].reset_index(drop=True)\n",
    "\n",
    "baseline_mae = np.mean(np.abs(val_df[\"target\"] - val_df[\"flow_lag_1\"]))\n",
    "baseline_rmse = np.sqrt(np.mean((val_df[\"target\"] - val_df[\"flow_lag_1\"]) ** 2))\n",
    "print(\"Baseline (flow_lag_1) BEFORE LSTM:\")\n",
    "print(f\"MAE  : {baseline_mae:,.2f}\")\n",
    "print(f\"RMSE : {baseline_rmse:,.2f}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Build sequences per station\n",
    "possible_features = [\n",
    "    \"flow_norm\", \"is_weekend\", \"day_of_week_num\", \"day_of_month\", \"week_of_year\",\n",
    "    \"flow_lag_1\", \"flow_lag_7\", \"flow_lag_14\", \"flow_roll_mean_7\", \"flow_roll_mean_14\",\n",
    "    \"flow_roll_std_7\", \"flow_roll_std_14\", \"flow_ratio\", \"flow_diff\"\n",
    "]\n",
    "if \"latitude\" in df.columns and \"longitude\" in df.columns:\n",
    "    possible_features += [\"latitude\", \"longitude\"]\n",
    "\n",
    "FEATURE_COLS = [col for col in possible_features if col in df.columns]\n",
    "print(\"Using features:\", FEATURE_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e047f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2238141\n",
      "Val samples  : 553566\n"
     ]
    }
   ],
   "source": [
    "class SubwaySeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item:\n",
    "      X: (SEQ_LEN, F) features for days t-SEQ_LEN+1..t\n",
    "      y: scalar flow_norm at day t+1\n",
    "      meta: station_key, date_of_y, mean, std (for denorm)\n",
    "    \"\"\"\n",
    "    def __init__(self, frame: pd.DataFrame, seq_len: int, feature_cols: list[str]):\n",
    "        self.seq_len = seq_len\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "        self.samples = []\n",
    "        for st, g in frame.groupby(\"station_key\"):\n",
    "            g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "            if len(g) < seq_len + 1:\n",
    "                continue\n",
    "\n",
    "            feats = g[feature_cols].to_numpy(dtype=np.float32)\n",
    "            y = g[\"flow_norm\"].to_numpy(dtype=np.float32)\n",
    "            mu = g[\"mean\"].to_numpy(dtype=np.float32)\n",
    "            sd = g[\"std\"].to_numpy(dtype=np.float32)\n",
    "            dates = g[DATE_COL].dt.strftime(\"%Y-%m-%d\").astype(str).to_numpy()\n",
    "\n",
    "            for t in range(seq_len - 1, len(g) - 1):\n",
    "                X = feats[t - (seq_len - 1): t + 1]\n",
    "                target = y[t + 1]\n",
    "                meta = {\n",
    "                    \"station_key\": str(st),\n",
    "                    \"date_y\": dates[t + 1],\n",
    "                    \"mean\": float(mu[t + 1]),\n",
    "                    \"std\": float(sd[t + 1]),\n",
    "                }\n",
    "                self.samples.append((X, target, meta))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y, meta = self.samples[idx]\n",
    "        return torch.from_numpy(X), torch.tensor(y, dtype=torch.float32), meta\n",
    "\n",
    "train_ds = SubwaySeqDataset(train_df, SEQ_LEN, FEATURE_COLS)\n",
    "val_ds = SubwaySeqDataset(val_df, SEQ_LEN, FEATURE_COLS)\n",
    "\n",
    "print(\"Train samples:\", len(train_ds))\n",
    "print(\"Val samples  :\", len(val_ds))\n",
    "\n",
    "def custom_collate(batch):\n",
    "    Xs, ys, metas = zip(*batch)\n",
    "    return torch.stack(Xs), torch.stack(ys), list(metas)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dbb6d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | train_loss=0.75132 | val_MAE=8,400.99 | val_RMSE=16,401.97\n",
      "Epoch 2/20 | train_loss=0.72632 | val_MAE=8,467.49 | val_RMSE=16,448.53\n",
      "Epoch 3/20 | train_loss=0.70867 | val_MAE=8,495.47 | val_RMSE=16,341.87\n",
      "Epoch 4/20 | train_loss=0.69036 | val_MAE=8,537.90 | val_RMSE=16,326.05\n",
      "Epoch 5/20 | train_loss=0.68644 | val_MAE=8,431.42 | val_RMSE=16,302.08\n",
      "Epoch 6/20 | train_loss=0.67639 | val_MAE=8,365.62 | val_RMSE=16,250.06\n",
      "Epoch 7/20 | train_loss=0.67526 | val_MAE=8,460.75 | val_RMSE=16,294.00\n",
      "Epoch 8/20 | train_loss=0.66491 | val_MAE=8,297.89 | val_RMSE=16,185.11\n",
      "Epoch 9/20 | train_loss=0.66112 | val_MAE=8,280.12 | val_RMSE=16,175.31\n",
      "Epoch 10/20 | train_loss=0.66350 | val_MAE=8,400.32 | val_RMSE=16,201.09\n",
      "Epoch 11/20 | train_loss=0.66475 | val_MAE=8,344.33 | val_RMSE=16,209.36\n",
      "Epoch 12/20 | train_loss=0.65701 | val_MAE=8,352.83 | val_RMSE=16,144.50\n",
      "Epoch 13/20 | train_loss=0.66644 | val_MAE=8,397.25 | val_RMSE=16,215.63\n",
      "Epoch 14/20 | train_loss=0.66151 | val_MAE=8,313.12 | val_RMSE=16,097.48\n",
      "Epoch 15/20 | train_loss=0.65722 | val_MAE=8,380.25 | val_RMSE=16,155.88\n",
      "Epoch 16/20 | train_loss=0.64724 | val_MAE=8,310.26 | val_RMSE=16,120.19\n",
      "Epoch 17/20 | train_loss=0.64375 | val_MAE=8,245.78 | val_RMSE=16,119.74\n",
      "Epoch 18/20 | train_loss=0.64987 | val_MAE=8,212.36 | val_RMSE=16,052.96\n",
      "Epoch 19/20 | train_loss=0.64643 | val_MAE=8,321.40 | val_RMSE=16,082.42\n",
      "Epoch 20/20 | train_loss=0.63703 | val_MAE=8,266.96 | val_RMSE=16,047.04\n",
      "\n",
      "LSTM Results (Validation Set)\n",
      "MAE  : 8,266.96\n",
      "RMSE : 16,047.04\n",
      "----------------------------------------\n",
      "Improvement over baseline\n",
      "MAE improvement  : 27.11%\n",
      "RMSE improvement : 32.66%\n"
     ]
    }
   ],
   "source": [
    "# Model: LSTM\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.head(last).squeeze(-1)\n",
    "\n",
    "model = LSTMRegressor(input_size=len(FEATURE_COLS)).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    preds_norm, trues_norm, metas = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y, meta in loader:\n",
    "            X = X.to(DEVICE, dtype=torch.float32)\n",
    "            y = y.to(DEVICE, dtype=torch.float32)\n",
    "            yhat = model(X)\n",
    "            preds_norm.append(yhat.detach().cpu().numpy())\n",
    "            trues_norm.append(y.detach().cpu().numpy())\n",
    "            if isinstance(meta, dict):\n",
    "                metas.append(meta)\n",
    "            else:\n",
    "                metas.extend(list(meta))\n",
    "    preds_norm = np.concatenate(preds_norm)\n",
    "    trues_norm = np.concatenate(trues_norm)\n",
    "    mu = np.array([m[\"mean\"] for m in metas], dtype=np.float32)\n",
    "    sd = np.array([m[\"std\"] for m in metas], dtype=np.float32)\n",
    "    preds = preds_norm * sd + mu\n",
    "    trues = trues_norm * sd + mu\n",
    "    mae = float(np.mean(np.abs(preds - trues)))\n",
    "    rmse = float(math.sqrt(np.mean((preds - trues) ** 2)))\n",
    "    return mae, rmse, preds, trues, metas\n",
    "\n",
    "history = {\"train_loss\": [], \"val_mae\": [], \"val_rmse\": []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for X, y, _ in train_loader:\n",
    "        X = X.to(DEVICE, dtype=torch.float32)\n",
    "        y = y.to(DEVICE, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(X)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running += float(loss.item())\n",
    "    train_loss = running / max(1, len(train_loader))\n",
    "    val_mae, val_rmse, _, _, _ = eval_loader(val_loader)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_mae\"].append(val_mae)\n",
    "    history[\"val_rmse\"].append(val_rmse)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train_loss={train_loss:.5f} | val_MAE={val_mae:,.2f} | val_RMSE={val_rmse:,.2f}\")\n",
    "\n",
    "val_mae, val_rmse, preds, trues, metas = eval_loader(val_loader)\n",
    "\n",
    "print(\"\\nLSTM Results (Validation Set)\")\n",
    "print(f\"MAE  : {val_mae:,.2f}\")\n",
    "print(f\"RMSE : {val_rmse:,.2f}\")\n",
    "print(\"-\"*40)\n",
    "print(\"Improvement over baseline\")\n",
    "print(f\"MAE improvement  : {(baseline_mae - val_mae) / baseline_mae * 100:.2f}%\")\n",
    "print(f\"RMSE improvement : {(baseline_rmse - val_rmse) / baseline_rmse * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
