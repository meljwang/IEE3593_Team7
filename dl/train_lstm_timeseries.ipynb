{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0627b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a30cee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_PATH = BASE_DIR / \"dataset\" / \"card_usage\" / \"card_subway_with_timeseries_features.csv\"\n",
    "OUT_DIR = BASE_DIR / \"ml_outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATE_COL = \"date\"\n",
    "TARGET_COL = \"total_flow\"\n",
    "\n",
    "SEQ_LEN = 14\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08f98d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATE_COL = \"date\"\n",
    "TARGET_COL = \"total_flow\"\n",
    "\n",
    "ROOT = Path.cwd().parent   \n",
    "DATA_PATH = ROOT / \"dataset\" / \"card_usage\" / \"card_subway_transform_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[DATE_COL], low_memory=False)\n",
    "\n",
    "\n",
    "# numeric cleanup\n",
    "for col in [\"boardings\", \"alightings\", \"latitude\", \"longitude\", \"station_code\", \"seoulmetro_code\", TARGET_COL]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# weekend -> int\n",
    "if \"is_weekend\" in df.columns:\n",
    "    df[\"is_weekend\"] = pd.to_numeric(df[\"is_weekend\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "else:\n",
    "    df[\"is_weekend\"] = (df[DATE_COL].dt.weekday >= 5).astype(int)\n",
    "\n",
    "# station_key\n",
    "code = None\n",
    "if \"seoulmetro_code\" in df.columns:\n",
    "    code = df[\"seoulmetro_code\"]\n",
    "elif \"station_code\" in df.columns:\n",
    "    code = df[\"station_code\"]\n",
    "\n",
    "if code is not None:\n",
    "    code_int = code.fillna(-1).astype(int)\n",
    "    df[\"station_key\"] = np.where(\n",
    "        code.notna() & (code.astype(float) > 0),\n",
    "        code_int.astype(str),\n",
    "        df[\"line\"].astype(str) + \"|\" + df[\"station_kr\"].astype(str)\n",
    "    )\n",
    "else:\n",
    "    df[\"station_key\"] = df[\"line\"].astype(str) + \"|\" + df[\"station_kr\"].astype(str)\n",
    "\n",
    "df = df.sort_values([\"station_key\", DATE_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e25a7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df[\"day_of_week_num\"] = df[DATE_COL].dt.dayofweek\n",
    "df[\"day_of_month\"] = df[DATE_COL].dt.day\n",
    "df[\"week_of_year\"] = df[DATE_COL].dt.isocalendar().week.astype(int)\n",
    "df[\"flow_ratio\"] = df[\"boardings\"] / (df[\"alightings\"] + 1)\n",
    "df[\"flow_diff\"] = df[\"boardings\"] - df[\"alightings\"]\n",
    "\n",
    "LAGS = [1, 7, 14]\n",
    "for lag in LAGS:\n",
    "    df[f\"flow_lag_{lag}\"] = df.groupby(\"station_key\")[TARGET_COL].shift(lag)\n",
    "\n",
    "ROLL_WINDOWS = [7, 14]\n",
    "for w in ROLL_WINDOWS:\n",
    "    df[f\"flow_roll_mean_{w}\"] = df.groupby(\"station_key\")[TARGET_COL].transform(\n",
    "        lambda s: s.shift(1).rolling(w, min_periods=w).mean()\n",
    "    )\n",
    "    df[f\"flow_roll_std_{w}\"] = df.groupby(\"station_key\")[TARGET_COL].transform(\n",
    "        lambda s: s.shift(1).rolling(w, min_periods=w).std()\n",
    "    )\n",
    "\n",
    "# Target: next day flow\n",
    "df[\"target\"] = df.groupby(\"station_key\")[TARGET_COL].shift(-1)\n",
    "\n",
    "FEATURES = [\n",
    "    \"flow_lag_1\", \"flow_lag_7\", \"flow_lag_14\",\n",
    "    \"flow_roll_mean_7\", \"flow_roll_mean_14\",\n",
    "    \"flow_roll_std_7\", \"flow_roll_std_14\",\n",
    "    \"flow_ratio\", \"flow_diff\",\n",
    "    \"day_of_week_num\", \"day_of_month\", \"week_of_year\",\n",
    "    \"is_weekend\"\n",
    "]\n",
    "for g in [\"latitude\", \"longitude\"]:\n",
    "    if g in df.columns:\n",
    "        FEATURES.append(g)\n",
    "\n",
    "needed = FEATURES + [\"target\", DATE_COL, \"station_key\"]\n",
    "df_model = df.dropna(subset=needed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89c511cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (flow_lag_1) BEFORE LSTM:\n",
      "MAE  : 11,342.17\n",
      "RMSE : 23,829.96\n",
      "----------------------------------------\n",
      "Using features: ['is_weekend', 'day_of_week_num', 'day_of_month', 'week_of_year', 'flow_lag_1', 'flow_lag_7', 'flow_lag_14', 'flow_roll_mean_7', 'flow_roll_mean_14', 'flow_roll_std_7', 'flow_roll_std_14', 'flow_ratio', 'flow_diff', 'latitude', 'longitude']\n"
     ]
    }
   ],
   "source": [
    "# Time split\n",
    "split_date = df_model[DATE_COL].quantile(0.8)\n",
    "train_df = df_model[df_model[DATE_COL] <= split_date].copy()\n",
    "val_df = df_model[df_model[DATE_COL] > split_date].copy()\n",
    "\n",
    "# Per-station normalization\n",
    "stats = train_df.groupby(\"station_key\")[TARGET_COL].agg([\"mean\", \"std\"]).reset_index()\n",
    "stats[\"std\"] = stats[\"std\"].replace(0, np.nan)\n",
    "stats = stats.fillna({\"std\": 1.0})\n",
    "\n",
    "train_df = train_df.merge(stats, on=\"station_key\", how=\"left\")\n",
    "val_df = val_df.merge(stats, on=\"station_key\", how=\"left\")\n",
    "\n",
    "train_df[\"flow_norm\"] = (train_df[TARGET_COL] - train_df[\"mean\"]) / train_df[\"std\"]\n",
    "val_df[\"flow_norm\"] = (val_df[TARGET_COL] - val_df[\"mean\"]) / val_df[\"std\"]\n",
    "\n",
    "val_df[\"mean\"] = val_df[\"mean\"].fillna(val_df[TARGET_COL].mean())\n",
    "val_df[\"std\"] = val_df[\"std\"].fillna(val_df[TARGET_COL].std() if val_df[TARGET_COL].std() > 0 else 1.0)\n",
    "val_df[\"flow_norm\"] = (val_df[TARGET_COL] - val_df[\"mean\"]) / val_df[\"std\"]\n",
    "\n",
    "# --- Filter out rows with NaN flow_lag_1 to match LGBM baseline ---\n",
    "val_df = val_df[val_df[\"flow_lag_1\"].notna()].reset_index(drop=True)\n",
    "\n",
    "# Calculate and print baseline BEFORE LSTM (on all valid val_df rows)\n",
    "baseline_mae = np.mean(np.abs(val_df[\"target\"] - val_df[\"flow_lag_1\"]))\n",
    "baseline_rmse = np.sqrt(np.mean((val_df[\"target\"] - val_df[\"flow_lag_1\"]) ** 2))\n",
    "print(\"Baseline (flow_lag_1) BEFORE LSTM:\")\n",
    "print(f\"MAE  : {baseline_mae:,.2f}\")\n",
    "print(f\"RMSE : {baseline_rmse:,.2f}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Build sequences per station\n",
    "possible_features = [\n",
    "    \"flow_norm\", \"is_weekend\", \"day_of_week_num\", \"day_of_month\", \"week_of_year\",\n",
    "    \"flow_lag_1\", \"flow_lag_7\", \"flow_lag_14\", \"flow_roll_mean_7\", \"flow_roll_mean_14\",\n",
    "    \"flow_roll_std_7\", \"flow_roll_std_14\", \"flow_ratio\", \"flow_diff\"\n",
    "]\n",
    "if \"latitude\" in df.columns and \"longitude\" in df.columns:\n",
    "    possible_features += [\"latitude\", \"longitude\"]\n",
    "\n",
    "FEATURE_COLS = [col for col in possible_features if col in df.columns]\n",
    "print(\"Using features:\", FEATURE_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2238141\n",
      "Val samples  : 553566\n"
     ]
    }
   ],
   "source": [
    "class SubwaySeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item:\n",
    "      X: (SEQ_LEN, F) features for days t-SEQ_LEN+1..t\n",
    "      y: scalar flow_norm at day t+1\n",
    "      meta: station_key, date_of_y, mean, std (for denorm)\n",
    "    \"\"\"\n",
    "    def __init__(self, frame: pd.DataFrame, seq_len: int, feature_cols: list[str]):\n",
    "        self.seq_len = seq_len\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "        self.samples = []\n",
    "        for st, g in frame.groupby(\"station_key\"):\n",
    "            g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "            if len(g) < seq_len + 1:\n",
    "                continue\n",
    "\n",
    "            feats = g[feature_cols].to_numpy(dtype=np.float32)\n",
    "            y = g[\"flow_norm\"].to_numpy(dtype=np.float32)\n",
    "            mu = g[\"mean\"].to_numpy(dtype=np.float32)\n",
    "            sd = g[\"std\"].to_numpy(dtype=np.float32)\n",
    "            dates = g[DATE_COL].dt.strftime(\"%Y-%m-%d\").astype(str).to_numpy()\n",
    "\n",
    "            for t in range(seq_len - 1, len(g) - 1):\n",
    "                X = feats[t - (seq_len - 1): t + 1]\n",
    "                target = y[t + 1]\n",
    "                meta = {\n",
    "                    \"station_key\": str(st),\n",
    "                    \"date_y\": dates[t + 1],\n",
    "                    \"mean\": float(mu[t + 1]),\n",
    "                    \"std\": float(sd[t + 1]),\n",
    "                }\n",
    "                self.samples.append((X, target, meta))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y, meta = self.samples[idx]\n",
    "        return torch.from_numpy(X), torch.tensor(y, dtype=torch.float32), meta\n",
    "\n",
    "train_ds = SubwaySeqDataset(train_df, SEQ_LEN, FEATURE_COLS)\n",
    "val_ds = SubwaySeqDataset(val_df, SEQ_LEN, FEATURE_COLS)\n",
    "\n",
    "print(\"Train samples:\", len(train_ds))\n",
    "print(\"Val samples  :\", len(val_ds))\n",
    "\n",
    "def custom_collate(batch):\n",
    "    Xs, ys, metas = zip(*batch)\n",
    "    return torch.stack(Xs), torch.stack(ys), list(metas)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb6d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | train_loss=0.74701 | val_MAE=8,510.34 | val_RMSE=16,538.67\n",
      "Epoch 2/20 | train_loss=0.70634 | val_MAE=8,420.25 | val_RMSE=16,407.88\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m yhat = model(X)\n\u001b[32m     61\u001b[39m loss = criterion(yhat, y)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m     64\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Model: LSTM\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.head(last).squeeze(-1)\n",
    "\n",
    "model = LSTMRegressor(input_size=len(FEATURE_COLS)).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    preds_norm, trues_norm, metas = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y, meta in loader:\n",
    "            X = X.to(DEVICE, dtype=torch.float32)\n",
    "            y = y.to(DEVICE, dtype=torch.float32)\n",
    "            yhat = model(X)\n",
    "            preds_norm.append(yhat.detach().cpu().numpy())\n",
    "            trues_norm.append(y.detach().cpu().numpy())\n",
    "            if isinstance(meta, dict):\n",
    "                metas.append(meta)\n",
    "            else:\n",
    "                metas.extend(list(meta))\n",
    "    preds_norm = np.concatenate(preds_norm)\n",
    "    trues_norm = np.concatenate(trues_norm)\n",
    "    mu = np.array([m[\"mean\"] for m in metas], dtype=np.float32)\n",
    "    sd = np.array([m[\"std\"] for m in metas], dtype=np.float32)\n",
    "    preds = preds_norm * sd + mu\n",
    "    trues = trues_norm * sd + mu\n",
    "    mae = float(np.mean(np.abs(preds - trues)))\n",
    "    rmse = float(math.sqrt(np.mean((preds - trues) ** 2)))\n",
    "    return mae, rmse, preds, trues, metas\n",
    "\n",
    "history = {\"train_loss\": [], \"val_mae\": [], \"val_rmse\": []}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for X, y, _ in train_loader:\n",
    "        X = X.to(DEVICE, dtype=torch.float32)\n",
    "        y = y.to(DEVICE, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(X)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running += float(loss.item())\n",
    "    train_loss = running / max(1, len(train_loader))\n",
    "    val_mae, val_rmse, _, _, _ = eval_loader(val_loader)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_mae\"].append(val_mae)\n",
    "    history[\"val_rmse\"].append(val_rmse)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train_loss={train_loss:.5f} | val_MAE={val_mae:,.2f} | val_RMSE={val_rmse:,.2f}\")\n",
    "\n",
    "val_mae, val_rmse, preds, trues, metas = eval_loader(val_loader)\n",
    "\n",
    "print(\"\\nLSTM Results (Validation Set)\")\n",
    "print(f\"MAE  : {val_mae:,.2f}\")\n",
    "print(f\"RMSE : {val_rmse:,.2f}\")\n",
    "print(\"-\"*40)\n",
    "print(\"Improvement over baseline\")\n",
    "print(f\"MAE improvement  : {(baseline_mae - val_mae) / baseline_mae * 100:.2f}%\")\n",
    "print(f\"RMSE improvement : {(baseline_rmse - val_rmse) / baseline_rmse * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
